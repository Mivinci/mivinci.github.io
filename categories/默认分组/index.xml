<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>默认分组 on 被门夹过的核桃还补脑吗</title><link>https://xjj.pub/categories/%E9%BB%98%E8%AE%A4%E5%88%86%E7%BB%84/</link><description>Recent content in 默认分组 on 被门夹过的核桃还补脑吗</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>© XJJ 2021</copyright><lastBuildDate>Sat, 13 Nov 2021 18:33:48 +0800</lastBuildDate><atom:link href="https://xjj.pub/categories/%E9%BB%98%E8%AE%A4%E5%88%86%E7%BB%84/index.xml" rel="self" type="application/rss+xml"/><item><title>关于 Minima 这个主题</title><link>https://xjj.pub/idea/something-about-minima/</link><pubDate>Sat, 13 Nov 2021 18:33:48 +0800</pubDate><guid>https://xjj.pub/idea/something-about-minima/</guid><description>距离 Minima 的第一次代码提交已经过去 3 个月了，中间经历了很多次迭代，有小功能的添加，也有界面的大改，从来没有哪个项目让我坚持维护了这么久，这可能就是社区驱动的优势（虽然可能只有一两人在用，哈哈）。不过，重要的不是有几个人在用，而是时不时会受到邮件或是 GitHub 发来的 issue 通知，告知我哪里有 bug 或是希望我加个什么新功能，这时候就会让我有维护下去的动力。不过他们可能只是在尝试不同的主题，并不会真的使用我的，就像我最开始玩自建博客的时候一样，花很多时间来挑主题，结果最后还是自己写了一个，嚯嚯。
截止到现在，Minima 只获得了 12 个 star 和 11 个 fork，哈哈有点惨，不过有人会 fork 我是没想到的，估计是想自己拿去改改吧。上个月收到一个 PR，帮我改了一个首页的 bug，我看代码没问题就直接给合并了（原来 PR 被合并后就能自动成为 contributor）刚刚去 他主页 看了看，还在用我的主题，不过他稍微改了改样式，哈哈。
Minima 原本是 Hexo 的一个主题，因为其实一直都想写个 Hugo 主题来用，所以就去 Hexo 的 主题官网 找了个喜欢的来抄了抄 UI，于是就看到了 Minima。一是因为我本来就喜欢极简风格的主题，二是这种风格的界面好实现，没有很花哨的动画。其实 Hugo 的主题很多都是极简的（因为 Hugo 是 Go 语言开发的，所以很多主题作者可能不是前端出身，也就没有很多很炫的 UI）。不过我觉得 Hugo 的极简主题还是差了点设计感，也有些过于简单了，一直没找到能满足我需求的主题。
目前，我的 Hugo 版 Minima 仍保留了原版 Minima 的所有功能，包括暗黑模式、分类和标签索引等，另外还增加了 KaTeX 和 Mermaid 支持，因为我很多时候写的东西里面需要显示公式和图表，在 示例网页 可以查看效果。另外原版 Minima 的 VSCode 风格的代码高亮是我见过做的最好的，所以当时花了很久，才将代码高亮调得和原版比较接近，因为在代码关键字识别准确度上 Hugo 还是比 Hexo 要弱一点。</description></item><item><title>更令人失望的高等教育</title><link>https://xjj.pub/idea/disapointing_education/</link><pubDate>Fri, 01 Oct 2021 22:44:16 +0800</pubDate><guid>https://xjj.pub/idea/disapointing_education/</guid><description>当了一个月的硕士研究生（下简称研究生），用一个词来形容的话，那只能是「失望」了。首先是垃圾的在线选课系统，我琢磨着就算是单机架构也不止这点并发能力。其次还是关于选课，按照学校要求，研究生需要在一年内修满 33 个学分（专硕少 5 分）。什么概念？就是研一除了政治英语这种必修，至少要上 8 门选修课&amp;hellip; 听上去好像不是很多对不对？可一次课为 4 节连上，加上中途 3 个短暂的课间共 210 分钟，上一次课就是一上午或一下午或一晚上。更离谱的是这些课均匀的分布在每一天&amp;hellip;
本科的时候我说过「上课影响学习，不上课影响学位」，这不还得说 3 年·。我不是说研究生上课不好，只能说是跟好一点也不沾边，当然政治课除外 233。很多课根本就没必要开设，比如像什么面向对象设计模式啥啥的，这种东西是个脑子正常的人都能花几个小时阅读完搓点代码就会了。非要硬生生开 32 个学时，我人傻了都&amp;hellip;
还有机器学习入门和一系列带高级的课程，哪一个不是能买本靠谱的书最多一个月就能自学完的。对于一些天赋选手，半个月都绰绰有余。然而现实是这些课都是 32 学时起步。
就为了应付这些课程和考试，就会花掉研一大半的时间和精力，我琢磨着各个都是人上人呢，光靠研二一年就能完成科研并发表有效论文。噢忘了！大多都是为了毕业才凑论文的，那没事了。
毫不夸张地说，就计算机学科而言，这些专业课程都是本科应该完成的。哦对，本科也是为了上课而拉时长，没时间学这么多，呵呵。
不过我想这也是必然的结果。除开一些人文和数学上的基础课外，本科的后三年完全有可能通过自学成为一个领域的专家，同时拥有较广阔的知识体系。然而现实是学校开设了又长又没用的必选修课来充斥学生枯燥的生活。
这种教学方式简直是毒药。在这种模式下，确实让大部分人，特别是享乐主义，以一个修完专业课程毕业生的身份，顺利找到工作。实际上工作才使他们正式开始学习生涯&amp;hellip; 而他们的学位也仅仅是个身份。
对于一部分对工作不满意，或是压根没找到工作的人，他们选择了继续读书，而这部分人却是研究生里的绝大多数，所以研究生新生的质量是很低的，很难不这样说。
研究生，可能是他们给自己的第二次机会，如果在和本科同样的模式下培养，那这瓶毒药，只会让他们换个听上去似乎更高级的身份，找到一份本科生就能找到工作，甚至更差。
可能会有人说我在崇尚内卷，很难不反对，内卷这个词已经被玩儿得成为工作学习的同义词了。只要有人在学习，在工作，就会被说成在卷，好像是什么见不得光的事情一样。的确，在大学寝室只要有人学习就会被嘲讽，学习已经变成需要偷偷摸摸进行的事情了 233&amp;hellip;
这种人一般是恐惧知识的，试图通过嘲讽别人来证明自己的价值。现有的高等教育模式是给这类人的福利，让他们不通过有效学习就能获得和其他人一样的待遇和结果，所以他们其实是聪明的。
我同时也极其讨厌像上进、努力、学霸这些说法，我觉得很多被当作需要所谓努力的事情，都是这个时代对人类的基本要求，但大部分人都在自己的制度和要求中圈地自萌，甚至要求别人遵循他的制度。我认为当一个人在挑战也许不可能完成的事情的时候才配得上努力这类词。</description></item><item><title>哈喽 👋</title><link>https://xjj.pub/about/</link><pubDate>Sun, 18 Jul 2021 11:24:06 +0800</pubDate><guid>https://xjj.pub/about/</guid><description>我是 XJJ，不是洗洁精也没有想静静，你可能是通过我的网名「被门夹过的核桃还补脑吗」认识我的，当然现在也叫小丽。我同时也是：
理想主义者 喜欢理论物理学 会点技术 义务教育漏网之鱼 这是我第三次开始写博客，之前两次没能坚持下去可能都是因为使用了别人的博客主题(借口)，所以这次索性先写了个主题再搭博客。目前已经可以在 Hugo 主题官网 上下载这款叫 Minima 的主题。同时，该主题集成了我写的一个评论插件 OvO。和 Waline 一样，OvO 可以嵌入在其他网页上，为其提供评论功能。
为什么非要写博客？诶，就是玩儿！😅
哈哈, 言归正传。为什么还是想写博客？引用句最符合动机的话：
我不是程序员，也不是设计师，我只是恰好有一些想法和一台电脑。
没错，就是平时脑子里充斥着很多想法，无论是技术上的还是生活上的，也无论是熟悉的领域的还是不熟悉的领域的。有的会驱动我发掘，有的会使我去实现，还有的会让我反感。时间久了，有些想法还会重复出现。所以，当我尝试着将这些想法记录下来后，会有一种解脱的感觉，就像是脑子里有个任务队列，队头等着被执行。不过，由于平时并没有较多的精力来记录，所以你会看到前几年只有稀稀散散几篇文章，不过我想今后应该会有所改善，并尽量多记录下学习上，像计算机底层原理、开源项目源码分析等等，随便安利自己的玩具项目哈哈。
另外，写博客可能会给你的学习过程或生活设置存档点，日后翻看自己写的东西时，能够激发重新学习相关内容的动力和机会，因为你也许会忘记曾经几时见到学到些什么。这也就是为什么我一直建议不要把经别人压缩提炼后的知识当做自己的知识，而是应该通过那些总结，找到相关书籍或文献进行系统地学习。
最后，有些文章中表达的想法可能比较激进，就当我是在圈地自萌吧～</description></item><item><title>万物皆弹簧</title><link>https://xjj.pub/idea/tayor-expansion/</link><pubDate>Mon, 03 Feb 2020 18:34:00 +0800</pubDate><guid>https://xjj.pub/idea/tayor-expansion/</guid><description>你要是上过幼儿园小班呢，应该知道势能是位置的函数，表示为 $V(\textbf{r})$，其中 $\textbf{r}$是位矢。在一范围内若某个点的势能达到极小值，则称该点为稳态点 $\textbf{r}_s$，即
对势能函数在稳态点使用泰勒展开并忽略 2 阶后的项得到
$$ V(\textbf{r})=V(\textbf{r}_s)+V^{'}(\textbf{r}_s)(\textbf{r}-\textbf{r}_s)+\frac{V^{''}(\textbf{r}_s)}{2!}(\textbf{r}-\textbf{r}_s)^2 $$
然后把稳态点当作零势能参考点，则有
$$ V(\textbf{r}_s)=0 $$
联立这三个式子得到稳态点处势能的低阶近似为
$$ V(\textbf{r})\approx\frac{V^{''}(\textbf{r}_s)}{2!}(\textbf{r}-\textbf{r}_s)^2 $$
这是势能关于位置的二次函数，其中 $V^{''}(\textbf{r}_s)$ 为某个常数 $k$。
到这儿，要是你还有幸上过幼儿园大班的话，应该知道「力」是势能对位置的导数，所以稳态点附近的粒子受到的力为
$$ \textbf{F}(\textbf{r})=-\frac{dV(\textbf{r})}{d\textbf{r}}=-k(\textbf{r}-\textbf{r}_s) $$
其中 $\textbf{r}-\textbf{r}_s$ 表示在稳态点附近的位移变化，用 $\Delta{\textbf{r}}$ 表示吧。
若是一维的情况，上式变为
$$ \textbf{F}(\textbf{x})=-k\Delta{\textbf{x}} $$
这不就是「胡克定律」吗，即弹簧的弹力与其位移变化量成正比。其中的负号表示该力为吸引力。
这告诉我们在稳态点附近的受力情况可以不依赖势能函数的具体形式，只跟位置变化量成正比关系，近似一种弹簧的弹力。
出现在稳态点附近的运动无处不在，小到固体中原子因与附近原子相互作用而产生的震动，大到你这几天躺床上强行被叫起来吃饭时心里产生的扰动，都可以看成是弹力的作用。所以人类的本质其实是弹簧，你越处在使自己舒适的地方，你就越靠近你的稳态点，你受力的低阶近似就越精确，你就越是根弹簧。</description></item><item><title>关于「信息量大」这句话</title><link>https://xjj.pub/idea/entropy/</link><pubDate>Fri, 03 Jan 2020 19:40:53 +0800</pubDate><guid>https://xjj.pub/idea/entropy/</guid><description>前几天在知乎上看到一个问题：一句话的信息量能大到什么程度？看到评论区很多回复像
对方正在输入&amp;hellip; 一切皆有可能 呵呵…… 之类的，还获得了很多的点赞。当时突然想什么是信息，什么又是信息量？当你面对一件事情，难道不是那些有用的数据对你来说才是信息吗，其他的干扰应该是噪声啊。比如你和一个人聊天，对方给你的回复才是信息呀，而显示 “对方正在输入&amp;hellip;”，并不会让你知道对方要说什么，这句话提供的信息仅仅是“对方正在干回复这件事儿”，而对方要回复的内容是什么，还是有很大的不确定性，这个不确定性是用信息熵来衡量的。
所以我们一直在把信息和信息熵混用。像上面三句话其实是信息熵很大，而信息量反而是很小的，因为你并不能从这些话里的出什么确切的结论。
”一切皆有可能“ 这句话更是直接告诉了你信息熵相当的大。为什么一切皆有可能？是因为你还没有得到足够多的信息来减小事情的不确定性。举个最简单的例子，你的沙雕同学抢了你的硬币，并让你猜在他哪只手里，在他告诉你答案之前，你对硬币在他哪只手是不确定的，现在他告诉你他的左手没有硬币，若他没有说谎，那么他就给了你信息，让你对硬币在他哪只手的不确定性从1降到了2/3，也就是说你的沙雕同学给你了1/3的信息，这1/3的信息通过声波传给了你。
故对于任何事情，你得通过各种方法去收集信息来消灭不确定性，减小信息熵。所以今晚吃什么 😵</description></item><item><title>怎么和最喜欢的人在一起？</title><link>https://xjj.pub/idea/e/</link><pubDate>Mon, 09 Dec 2019 01:40:53 +0800</pubDate><guid>https://xjj.pub/idea/e/</guid><description>你一生中会遇到很多的人，那么如何用最少的交往次数，找到最好的那个和他在一起呢？当然你说你就要全部试一遍，那我也阻止不了你。
首先，你可以先试着和几个人在一起(滑稽)，一段时间后，不管他们有多好，都甩了他们。然后接下来遇到的人，只要比前面被你甩的任何一个人好，就和他一起私奔。好了现在来把问题公式化一下(哎～别走呀，听我说完嘛)
假设有 n 个人，你要放弃前 k 个，从第 k+1 个开始，遇到比前 k 个好的就和他在一起，求 k 为多少使得最好的人被你选中的概率最大。
我们设
事件 $A$ 为：最好的人被你选中
事件 $B_i$ 为：第 i 个人是最好的
我们有全概率公式 $$ P(A)=\sum_{i=k+1}^{n}{P(B_i)P(A|B_i)} $$
其中，这 n 个人是均匀分布的，$P(B_i)$ 就为 $\frac{1}{n}$，所以只要求出 $P(A|B_i)$，就能算出最好的人被你选到的概率 $P(A)$ ，然后再使 $P(A)$ 的导数等于零，就能解出 k 了。
而 $P(A|B_i)$ 表示在第 i 个人是最好的那个人而这个人恰好被你选到的概率。那第 i-1 个就没有前 k 个好，而第 i-1 个没有前 k 个好的概率为 $\frac{k}{i-1}$，所以
$$ P(A)=\frac{1}{n}\sum_{i=k+1}^{n}{\frac{k}{i-1}}=\frac{k}{n}\sum_{i=k+1}^{n-1}{\frac{1}{i}} $$
假设 n 很大很大，也就是你会遇到很多很多的人，我们令 $x=\frac{k}{n}, f(t)=\frac{1}{t}$，上式可以转换为定积分
求 $P(A)$ 极值，令
$$ \frac{dP(A)}{dx}=\frac{d(-xlnx)}{dx}=1-lnx=0 $$
得到 $x=\frac{1}{e}$ ，所以 $k=\frac{n}{e} $</description></item><item><title>朴素贝叶斯分类器</title><link>https://xjj.pub/idea/bayes/</link><pubDate>Sun, 10 Nov 2019 13:52:53 +0800</pubDate><guid>https://xjj.pub/idea/bayes/</guid><description>这篇文章将对朴素贝叶斯分类器进行简单描述和公式推导，并以性别预测为例来理解其「朴素」的原因，最后你应该能根据文章的描述编写一个简单的由人的姓名预测其性别的小程序。阅读前你可能需要懂一些概率论的知识，比如条件概率、贝叶斯公式等等。
基本原理 我们在小学二年级学过贝叶斯公式：
$$ P(B|A)=\frac{P(B)P(A|B)}{P(A)} \tag{1} $$
通过该式子，我们可以算出在已知事件A发生的条件下，事件B发生的概率。比如1当我们看到室友抽屉里藏女士内衣，则室友是个变态的概率就是遇到变态室友的概率乘室友是个变态还喜欢把内衣放抽屉里的概率再除以室友抽屉里有内衣的概率。是不是非常的啊妹zing呀？这里面其实蕴含着「贝叶斯学派」独有的思想，即「后验概率」的思想。感兴趣的同学可以深入了解一下。
现在我们假设上式中的事件A由很多事件构成，即：
$$ A=A_1 \cap A_2 \cap &amp;hellip; \cap A_n $$
则我们的贝叶斯公式变成：
$$ P(B|A_1 A_2 &amp;hellip; A_n)=\frac{P(B)P(A_1 A_2 &amp;hellip; A_n|B)}{P(A_1 A_2 &amp;hellip; A_n)} \tag{2} $$
这其实已经是一个分类器的模型了。我们不妨将事件B看成一推数据的分类结果，将 $A_1,A_2,&amp;hellip;,A_n$ 看成是导致该结果的因素或者叫特征（以下统称特征），则等号左边表示的就是我们的数据属于分类 $B$ 的概率，当其达到某个阈值，我们可以认为该推数据就属于某个分类。
要得到等号左边是多少，我们得从已有的数据中找到等号右边的三项的值。其中 $P(B)$ 可以通过统计数据集中 $B$ 类样本出现的频次得到，即：
$$ P(B)=\frac{B类样本个数}{样本总个数} $$
但剩下的两项很难从有限的数据中直接得出。对于 $P(A_1 A_2 &amp;hellip; A_n|B)$，我们假设所有的特征相互独立，则我们就有： 2
$$ P(A_1 A_2 &amp;hellip; A_n|B)=\prod_{i=1}^{n}{P(A_i|B)} \tag{3} $$
其中 $P(A_i|B)$ 是容易从数据集中直接得到的，分为离散和连续两种情况：
当 $A_i$ 为离散型随机变量时 $$ P(A_i|B)=\frac{B类中有特征A_i的数据个数}{B类数据个数} $$
当 $A_i$ 为连续型随机变量时 假设 $A_i|B$ 符合期望为 $\mu_{ki}$，方差为 $\sigma^2_{ki}$ 的正态分布，则有：</description></item></channel></rss>